title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}

install.packages("randomForest")
library(randomForest)
library(dplyr)

str(iris)
dim(x = iris)

```
```{r}

data("mtcars")
str(mtcars)
mtcars$am<-as.factor(mtcars$am)
str(mtcars$am)

set.seed(99)
## Split index to split
split_index<-ceiling(0.6*nrow(mtcars))

## Do suffling
mtcars<- mtcars[sample(1:nrow(mtcars)),]

## 
train<- mtcars[1:split_index,]
test<-setdiff(mtcars,train)

str(train)
str(test)
```

```{r}
## construct the model
mtcars.rf<-randomForest(factor(am)~.,data = train,ntree=100,importance=TRUE)
mtcars.rf
str(mtcars.rf)
?randomForest

```

```{r}
plot(mtcars.rf)

```
```{r}
varImpPlot(mtcars.rf)
```
```{r}
predictions<-predict(mtcars.rf,newdata = test)
cbind(test,predictions)
table(predictions,test$am)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).
```{r}
## Example from the statistical Learning
require(MASS)

set.seed(101)
dim(Boston)
write.csv(Boston,"F:\\Data Scientist\\Day7\\Boston.csv")
train = sample(1:nrow(Boston),.7*nrow(Boston))
train_Data<- Boston[train,]
test_Data<- Boston[-train,]
`?`(Boston)
str(Boston)
library(randomForest)
Boston.rf<-randomForest(medv~.,data = train_Data)
Boston.rf
plot(Boston.rf)
varImpPlot(Boston.rf)
predictions<-predict(Boston.rf,data=test_Data)
cbind(test_Data$medv,predictions)
table(predictions,Boston[test,])
```

```{r}
MT_HBAT<- foreign::read.spss("E:/Multivariant ANalysis/Multivariate_Data_Analysis_7e_Datasets_and_Documentation/HBAT_200.sav",to.data.frame = TRUE)
MT_HBAT<- as.data.frame(MT_HBAT)
str(MT_HBAT)

set.seed(99)
## Split index to split
split_index<-ceiling(0.85*nrow(MT_HBAT))

## Do suffling
MT_HBAT<- MT_HBAT[sample(1:nrow(MT_HBAT)),]

## 
train<- MT_HBAT[1:split_index,]
test<-setdiff(MT_HBAT,train)

str(train)
str(test)

```

```{r}
MT_HBAT.rt<-randomForest(factor(train$x4)~.-id-split60-x1-x2-x3-x5,data=train,ntree=1000,importance=TRUE)
MT_HBAT.rt
plot(MT_HBAT.rt)
```
```{r}
varImpPlot(MT_HBAT.rt)
```

```{r}
predictions<-predict(MT_HBAT.rt,newdata = test)
cbind(test,predictions)
table(predictions,test$x4)
```

```{r}
termCrosssell<-read.csv("F:/Data Scientist/Day4/bank.csv",header=T,sep=";")
head(termCrosssell)
table(termCrosssell$y)
attach(termCrosssell)
str(termCrosssell)

```
```{r}
set.seed(99)
## Split index to split
split_index<-ceiling(0.6*nrow(termCrosssell))

## Do suffling
mtcars<- termCrosssell[sample(1:nrow(termCrosssell)),]

## 
train<- termCrosssell[1:split_index,]
test<-setdiff(termCrosssell,train)

cross_sell.rt<- randomForest(factor(y)~.,train, ntree=500,importance=TRUE)
plot(cross_sell.rt)


install.packages("caret"  )
install.packages("e1071")
# Load Library or packages
library(e1071)
library(caret)
# Create Confusion Matrix
confusionMatrix(data=factor(termCrossSell$y),
                reference=factor(termCrossSell$target),
                positive='1')
```
```{r}
varImpPlot(cross_sell.rt)
predictions<-predict(cross_sell.rt,newdata = test)
cbind(test,predictions)
table(predictions,test$y)

```

```{r}
UPSELL_PROPENSITY<-read.csv("E:/Multivariant ANalysis/Multivariate_Data_Analysis_7e_Datasets_and_Documentation/Practical/FEB_Report.txt",header=T,sep="|")
str(UPSELL_PROPENSITY)


par(mfrow=c(2,3))
hist(UPSELL_PROPENSITY$OLD_MOU,100)
hist(UPSELL_PROPENSITY$OLD_LOCAL_MOU,100)
hist(UPSELL_PROPENSITY$OLD_STD_MOU,100)
hist(UPSELL_PROPENSITY$OLD_THREE_MONTH_APRU,100)
hist(UPSELL_PROPENSITY$OLD_DEC_ARPU,100)
hist(UPSELL_PROPENSITY$OLD_ROAMING_MOU,100)

UPSELL_PROPENSITY$OLD_MOU[which(is.na(UPSELL_PROPENSITY$OLD_MOU))]=0
UPSELL_PROPENSITY$OLD_LOCAL_MOU[which(is.na(UPSELL_PROPENSITY$OLD_LOCAL_MOU))]=0
UPSELL_PROPENSITY$OLD_STD_MOU[which(is.na(UPSELL_PROPENSITY$OLD_STD_MOU))]=0
UPSELL_PROPENSITY$OLD_ROAMING_MOU[which(is.na(UPSELL_PROPENSITY$OLD_ROAMING_MOU))]=0
UPSELL_PROPENSITY$OLD_DEC_GPRS_USAGE[which(is.na(UPSELL_PROPENSITY$OLD_DEC_GPRS_USAGE))]=0
UPSELL_PROPENSITY$OLD_THREE_MONTH_APRU[which(is.na(UPSELL_PROPENSITY$OLD_THREE_MONTH_APRU))]=0
UPSELL_PROPENSITY$OLD_DEC_ARPU[which(is.na(UPSELL_PROPENSITY$OLD_DEC_ARPU))]=0

UPSELL_PROPENSITY$OLD_DEC_ARPU<-ifelse(test=UPSELL_PROPENSITY$OLD_DEC_ARPU<0,0,UPSELL_PROPENSITY$OLD_DEC_ARPU)
UPSELL_PROPENSITY$OLD_DEC_ARPU<-ifelse(UPSELL_PROPENSITY$OLD_DEC_ARPU!=0,log10(UPSELL_PROPENSITY$OLD_DEC_ARPU),0)

par(mfrow=c(1,1))
summary(UPSELL_PROPENSITY$OLD_DEC_ARPU[UPSELL_PROPENSITY$OLD_DEC_ARPU>=2])
hist(UPSELL_PROPENSITY$OLD_DEC_ARPU[UPSELL_PROPENSITY$OLD_DEC_ARPU>=2],100)
boxplot(UPSELL_PROPENSITY$OLD_DEC_ARPU[UPSELL_PROPENSITY$OLD_DEC_ARPU>=0])


UPSELL_PROPENSITY$OLD_THREE_MONTH_APRU<-ifelse(UPSELL_PROPENSITY$OLD_THREE_MONTH_APRU!=0,log10(UPSELL_PROPENSITY$OLD_THREE_MONTH_APRU),0)
hist(UPSELL_PROPENSITY$OLD_THREE_MONTH_APRU,100)


UPSELL_PROPENSITY$OLD_DEC_GPRS_USAGE<-ifelse(UPSELL_PROPENSITY$OLD_DEC_GPRS_USAGE>0,log10(UPSELL_PROPENSITY$OLD_DEC_GPRS_USAGE)^3,0)
hist(UPSELL_PROPENSITY$OLD_DEC_GPRS_USAGE,100)

UPSELL_PROPENSITY$OLD_MOU<-ifelse(UPSELL_PROPENSITY$OLD_MOU!=0,log10(UPSELL_PROPENSITY$OLD_MOU)^2,0)
hist(UPSELL_PROPENSITY$OLD_MOU,100)


UPSELL_PROPENSITY$OLD_LOCAL_MOU<-log10(UPSELL_PROPENSITY$OLD_LOCAL_MOU)^2
UPSELL_PROPENSITY$OLD_LOCAL_MOU[which(is.infinite(UPSELL_PROPENSITY$OLD_LOCAL_MOU))]<-0
hist(UPSELL_PROPENSITY$OLD_LOCAL_MOU,100)

UPSELL_PROPENSITY$OLD_STD_MOU<-log10(UPSELL_PROPENSITY$OLD_STD_MOU)
UPSELL_PROPENSITY$OLD_STD_MOU[which(is.infinite(UPSELL_PROPENSITY$OLD_STD_MOU))]<-0
hist(UPSELL_PROPENSITY$OLD_STD_MOU,100)

UPSELL_PROPENSITY$OLD_ROAMING_MOU<-log10(UPSELL_PROPENSITY$OLD_ROAMING_MOU)
UPSELL_PROPENSITY$OLD_ROAMING_MOU[which(is.infinite(UPSELL_PROPENSITY$OLD_ROAMING_MOU))]<-0
hist(UPSELL_PROPENSITY$OLD_ROAMING_MOU,100)

split_index<-ceiling(0.85*nrow(UPSELL_PROPENSITY))

## Do suffling
UPSELL_PROPENSITY<- UPSELL_PROPENSITY[sample(1:nrow(UPSELL_PROPENSITY)),]

## 
train<- UPSELL_PROPENSITY[1:split_index,]
test<-setdiff(UPSELL_PROPENSITY,train)

str(UPSELL_PROPENSITY)
UPSELL_PROPENSITY.rf<-randomForest(factor(UPSELL_DOWNGRADE)~ OLD_THREE_MONTH_APRU+OLD_DEC_GPRS_USAGE+OLD_LOCAL_MOU+OLD_STD_MOU+OLD_ROAMING_MOU,data=test,ntree=500,importance=TRUE)
UPSELL_PROPENSITY.rf
plot(UPSELL_PROPENSITY.rf)
```

```{r}
require(ISLR)
require(tree)

attach(Carseats)
hist(Sales)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats, High)
tree.carseats=tree(High~.-Sales,data=Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
tree.carseats

set.seed(1011)
train=sample(1:nrow(Carseats),250)
tree.carseats=tree(High~.-Sales,Carseats,subset=train)
plot(tree.carseats);text(tree.carseats,pretty=0)
tree.pred=predict(tree.carseats,Carseats[-train,],type="class")

```


```{r}
predicttions<-predict(UPSELL_PROPENSITY.rf,train)
cbind(train,predicttions)
table(predicttions,train$UPSELL_DOWNGRADE)

```

```{r}
str(iris)

set.seed(99)
## Split index to split
split_index<-ceiling(0.6*nrow(iris))

## Do suffling
mtcars<- mtcars[sample(1:nrow(iris)),]

## 
train<- iris[1:split_index,]
test<-setdiff(iris,train)

str(train)
str(test)

```

```{r}
iris.rf<- randomForest(factor(iris$Species)~.,data=iris,ntree=1000,importance=TRUE)
iris.rf
plot(iris.rf)
varImpPlot(iris.rf)
```

```{r}
str(iris)
iris.rf<- randomForest(Petal.Length ~.-Species,data=iris,ntree=1000,importance=TRUE)
iris.rf
plot(iris.rf)
varImpPlot(iris.rf)

```

